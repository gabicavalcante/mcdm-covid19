{
  
    
        "post0": {
            "title": "Global Mobility Report",
            "content": "Pacotes . %%shell pip install -U plotly pip install -U plotly-express #pip install -U pandas . Collecting plotly Downloading https://files.pythonhosted.org/packages/bf/5f/47ab0d9d843c5be0f5c5bd891736a4c84fa45c3b0a0ddb6b6df7c098c66f/plotly-4.9.0-py2.py3-none-any.whl (12.9MB) |████████████████████████████████| 12.9MB 307kB/s Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.15.0) Requirement already satisfied, skipping upgrade: retrying&gt;=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly) (1.3.3) Installing collected packages: plotly Found existing installation: plotly 4.4.1 Uninstalling plotly-4.4.1: Successfully uninstalled plotly-4.4.1 Successfully installed plotly-4.9.0 Collecting plotly-express Downloading https://files.pythonhosted.org/packages/d4/d6/8a2906f51e073a4be80cab35cfa10e7a34853e60f3ed5304ac470852a08d/plotly_express-0.4.1-py2.py3-none-any.whl Requirement already satisfied, skipping upgrade: scipy&gt;=0.18 in /usr/local/lib/python3.6/dist-packages (from plotly-express) (1.4.1) Requirement already satisfied, skipping upgrade: statsmodels&gt;=0.9.0 in /usr/local/lib/python3.6/dist-packages (from plotly-express) (0.10.2) Requirement already satisfied, skipping upgrade: patsy&gt;=0.5 in /usr/local/lib/python3.6/dist-packages (from plotly-express) (0.5.1) Requirement already satisfied, skipping upgrade: pandas&gt;=0.20.0 in /usr/local/lib/python3.6/dist-packages (from plotly-express) (1.0.5) Requirement already satisfied, skipping upgrade: plotly&gt;=4.1.0 in /usr/local/lib/python3.6/dist-packages (from plotly-express) (4.9.0) Requirement already satisfied, skipping upgrade: numpy&gt;=1.11 in /usr/local/lib/python3.6/dist-packages (from plotly-express) (1.18.5) Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from patsy&gt;=0.5-&gt;plotly-express) (1.15.0) Requirement already satisfied, skipping upgrade: python-dateutil&gt;=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas&gt;=0.20.0-&gt;plotly-express) (2.8.1) Requirement already satisfied, skipping upgrade: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas&gt;=0.20.0-&gt;plotly-express) (2018.9) Requirement already satisfied, skipping upgrade: retrying&gt;=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly&gt;=4.1.0-&gt;plotly-express) (1.3.3) Installing collected packages: plotly-express Successfully installed plotly-express-0.4.1 . . Esta célula demora um século! . %%shell pip install --upgrade Cython pip install --upgrade git+https://github.com/statsmodels/statsmodels . Requirement already up-to-date: Cython in /usr/local/lib/python3.6/dist-packages (0.29.21) Collecting git+https://github.com/statsmodels/statsmodels Cloning https://github.com/statsmodels/statsmodels to /tmp/pip-req-build-hehog4jd Running command git clone -q https://github.com/statsmodels/statsmodels /tmp/pip-req-build-hehog4jd Installing build dependencies ... done Getting requirements to build wheel ... done Preparing wheel metadata ... done Requirement already satisfied, skipping upgrade: scipy&gt;=1.1 in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.12.0rc0+13.gb6af4263d) (1.4.1) Requirement already satisfied, skipping upgrade: patsy&gt;=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.12.0rc0+13.gb6af4263d) (0.5.1) Requirement already satisfied, skipping upgrade: numpy&gt;=1.15 in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.12.0rc0+13.gb6af4263d) (1.18.5) Requirement already satisfied, skipping upgrade: pandas&gt;=0.21 in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.12.0rc0+13.gb6af4263d) (1.0.5) Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from patsy&gt;=0.5-&gt;statsmodels==0.12.0rc0+13.gb6af4263d) (1.15.0) Requirement already satisfied, skipping upgrade: python-dateutil&gt;=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas&gt;=0.21-&gt;statsmodels==0.12.0rc0+13.gb6af4263d) (2.8.1) Requirement already satisfied, skipping upgrade: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas&gt;=0.21-&gt;statsmodels==0.12.0rc0+13.gb6af4263d) (2018.9) Building wheels for collected packages: statsmodels Building wheel for statsmodels (PEP 517) ... done Created wheel for statsmodels: filename=statsmodels-0.12.0rc0+13.gb6af4263d-cp36-cp36m-linux_x86_64.whl size=17427203 sha256=f48fbb0ba1ce15c23cbbe8fb49460c9d01ad20968d38919b760536e256625226 Stored in directory: /tmp/pip-ephem-wheel-cache-ypzqcitq/wheels/7d/ad/45/ac1a03bd759c2fa74c486e2b1950d94b55f511b4c2b0418bd5 Successfully built statsmodels Installing collected packages: statsmodels Found existing installation: statsmodels 0.10.2 Uninstalling statsmodels-0.10.2: Successfully uninstalled statsmodels-0.10.2 Successfully installed statsmodels-0.12.0rc0+13.gb6af4263d . . !git clone https://mo-covid19:m0-c0v1d19@github.com/mo-covid19/mobility-covid19.git mo_covid19 . Cloning into &#39;mo_covid19&#39;... remote: Enumerating objects: 219, done. remote: Counting objects: 100% (219/219), done. remote: Compressing objects: 100% (135/135), done. remote: Total 219 (delta 125), reused 163 (delta 73), pack-reused 0 Receiving objects: 100% (219/219), 1006.02 KiB | 1.34 MiB/s, done. Resolving deltas: 100% (125/125), done. . from mo_covid19.data import * . Data extraction . Collection . locations_type = &quot;region&quot; data = collect_data(type_=locations_type) data.loc[data.locality_name == &#39;State of São Paulo&#39;, &#39;locality_name&#39;] = &quot;São Paulo&quot; data.loc[data.locality_name == &#39;State of Amazonas&#39;, &#39;locality_name&#39;] = &quot;Amazonas&quot; data.loc[data.locality_name == &#39;Lombardy&#39;, &#39;locality_name&#39;] = &quot;Lombardia&quot; long_regions = data.melt(id_vars=[&quot;locality_name&quot;, &quot;date&quot;], var_name=&quot;category&quot;, value_name=&quot;value&quot;) long_regions[&quot;date&quot;].max() . Timestamp(&#39;2020-08-16 00:00:00&#39;) . if locations_type == &quot;region&quot;: regions = [&quot;Île-de-France&quot;, &quot;Amazonas&quot;, &quot;São Paulo&quot;, &quot;Lombardia&quot;, &quot;New York&quot;] else: regions = [&quot;Japan&quot;, &quot;South Korea&quot;, &quot;Canada&quot;, &quot;Germany&quot;, &quot;Spain&quot;, &quot;Argentina&quot;, &quot;New Zealand&quot;] colors_sequence_category = [ &quot;#AB63FA&quot;, &quot;#19D3F3&quot;, &quot;#FF6692&quot;, &quot;#68BEBA&quot;, &quot;#FF7F0E&quot;, &quot;#8C564B&quot;, ] colors_sequence_locality = colors_sequence_category + [&quot;#DAA51F&quot;] colors_map_locality = dict(zip(regions, colors_sequence_locality)) . Filtering, renaming, and aggregating . Inspecting regions . fig = px.line(long_regions, x=&quot;date&quot;, y=&quot;value&quot;, color=&quot;category&quot;, labels=plotly_labels, color_discrete_sequence = colors_sequence_category, facet_col=&quot;locality_name&quot;, facet_col_wrap=2, height=800) fig.show() . . . Data preparation . adotamos a data de fechamento das escolas | . Enriching with dates . data_lockdown = { &quot;first_case_date&quot;: { &quot;Argentina&quot;: &quot;2020-03-04&quot;, &quot;Japan&quot;: &quot;2020-01-15&quot;, &quot;South Korea&quot;: &quot;2020-01-20&quot;, &quot;Canada&quot;: &quot;2020-01-26&quot;, &quot;Germany&quot;: &quot;2020-01-28&quot;, &quot;Spain&quot;: &quot;2020-02-01&quot;, &quot;Argentina&quot;: &quot;2020-03-04&quot;, &quot;New Zealand&quot;: &quot;2020-02-28&quot;, &quot;São Paulo&quot;: &quot;2020-02-26&quot;, &quot;Amazonas&quot;: &quot;2020-03-13&quot;, &quot;Île-de-France&quot;: &quot;2020-01-23&quot;, &quot;Lombardia&quot;: &quot;2020-02-14&quot;, &quot;New York&quot;: &quot;2020-03-01&quot;, }, &quot;restriction_date&quot;: { &quot;Argentina&quot;: &quot;2020-03-16&quot;, &quot;Japan&quot;: &quot;2020-03-02&quot;, &quot;South Korea&quot;: &quot;2020-02-22&quot;, &quot;Canada&quot;: &quot;2020-03-16&quot;, &quot;Germany&quot;:&quot;2020-03-16&quot;, &quot;Spain&quot;:&quot;2020-03-09&quot;, &quot;Argentina&quot;:&quot;2020-03-16&quot;, &quot;New Zealand&quot;:&quot;2020-03-24&quot;, &quot;São Paulo&quot;: &quot;2020-03-16&quot;, &quot;Amazonas&quot;: &quot;2020-03-16&quot;, &quot;Île-de-France&quot;: &quot;2020-03-12&quot;, &quot;Lombardia&quot;: &quot;2020-02-23&quot;, &quot;New York&quot;: &quot;2020-03-15&quot;, }, &quot;ease_restriction_date&quot;: { &quot;Argentina&quot;: &quot;2020-05-15&quot;, &quot;Japan&quot;: &quot;2020-05-15&quot;, &quot;South Korea&quot;: &quot;2020-05-15&quot;, &quot;Canada&quot;: &quot;2020-05-15&quot;, &quot;Germany&quot;: &quot;2020-05-15&quot;, &quot;Spain&quot;: &quot;2020-05-15&quot;, &quot;Argentina&quot;: &quot;2020-05-15&quot;, &quot;New Zealand&quot;: &quot;2020-05-15&quot;, &quot;São Paulo&quot;: &quot;2020-06-01&quot;, &quot;Amazonas&quot;: &quot;2020-05-31&quot;, &quot;Île-de-France&quot;: &quot;2020-05-11&quot;, &quot;Lombardia&quot;: &quot;2020-05-04&quot;, &quot;New York&quot;: &quot;2020-05-15&quot;, } } data_period = add_days_columns(data, data_lockdown) data_period.head() . date locality_name retail grocery_pharmacy parks transit_stations workplaces residential first_case_date restriction_date ease_restriction_date n_days_since_first_case n_days_since_restriction n_days_since_ease_restriction . 0 2020-02-15 | Lombardia | 3.076923 | -3.538462 | 42.307692 | 9.615385 | -1.076923 | -0.846154 | 2020-02-14 | 2020-02-23 | 2020-05-04 | 1 | -8 | -79 | . 1 2020-02-15 | New York | 9.096774 | -0.967742 | 16.892857 | 10.625000 | 0.387097 | -0.179487 | 2020-03-01 | 2020-03-15 | 2020-05-15 | -15 | -29 | -90 | . 2 2020-02-15 | Amazonas | -2.857143 | 5.750000 | -19.500000 | -5.333333 | 6.500000 | -1.000000 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -27 | -30 | -106 | . 3 2020-02-15 | São Paulo | 2.424528 | 1.944724 | 2.500000 | 1.007576 | 6.419355 | -0.676647 | 2020-02-26 | 2020-03-16 | 2020-06-01 | -11 | -30 | -107 | . 4 2020-02-15 | Île-de-France | -11.555556 | -10.444444 | 7.333333 | 3.222222 | -8.222222 | -1.222222 | 2020-01-23 | 2020-03-12 | 2020-05-11 | 23 | -26 | -86 | . import matplotlib.dates as mdates id_vars = [&quot;date&quot;, &quot;locality_name&quot;, &quot;first_case_date&quot;, &quot;restriction_date&quot;, &quot;ease_restriction_date&quot;, &quot;n_days_since_first_case&quot;, &quot;n_days_since_restriction&quot;, &quot;n_days_since_ease_restriction&quot;,] data_to_plot = data_period.melt( id_vars, var_name=&quot;category&quot;, value_name=&quot;value&quot; ).query(&#39;locality_name==&quot;Lombardia&quot; and category!=&quot;residential&quot; and date &lt;= &quot;2020-07-21&quot;&#39;) if locations_type == &quot;region&quot;: long_regions_plot = sns.relplot( x=&quot;date&quot;, y=&quot;value&quot;, hue=&quot;category&quot;, data = data_to_plot, col=&quot;locality_name&quot;, col_wrap=2, kind=&quot;line&quot;, height=6, legend=&quot;brief&quot;, aspect=1.5, markers=True, dashes=True ) long_regions_plot._legend.remove() # Iterate thorugh each axis for ax in long_regions_plot.axes: ax.set(xlabel=&#39;Date&#39;, ylabel=&#39;&#39;) handles, labels = ax.get_legend_handles_labels() if handles: set_labels = [&#39;Retail &amp; Recreation&#39;, &#39;Grocery &amp; Pharmacy&#39;, &#39;Parks&#39;, &#39;Transit Stations&#39;, &#39;Workplaces&#39;] #labels[1:] ax.legend(handles=handles[1:], labels=set_labels, title=&quot;&quot;, fontsize=11, title_fontsize=11) # Make x and y-axis labels slightly larger ax.set_xlabel(ax.get_xlabel(), fontsize=14) ax.set_ylabel(ax.get_ylabel(), fontsize=14) # Make title more human-readable and larger if ax.get_title(): ax.set_title(&quot;&quot;) #set ticks every week ax.xaxis.set_major_locator(mdates.WeekdayLocator()) #set major ticks format ax.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b&#39;)) ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=5)) # Make right ylabel more human-readable and larger if ax.texts: # This contains the right ylabel text txt = ax.texts[0] ax.text(txt.get_unitless_position()[0], txt.get_unitless_position()[1], txt.get_text().split(&#39;=&#39;)[1], transform=ax.transAxes, va=&#39;center&#39;, fontsize=&#39;xx-large&#39;) # Remove the original text ax.texts[0].remove() ax.fill_between(data_to_plot.query(&quot;50 &gt; n_days_since_restriction &gt;= 0&quot;)[&quot;date&quot;], -150, 100, color=&quot;gray&quot;, alpha=0.2) from datetime import datetime restriction_date = datetime.strptime(&#39;2020-02-23&#39;, &#39;%Y-%m-%d&#39;) ease_restriction_date = datetime.strptime(&quot;2020-05-11&quot;, &#39;%Y-%m-%d&#39;) plt.axvline(restriction_date, color=&#39;k&#39;, linestyle=&#39;dashed&#39;, linewidth=1) plt.axvline(ease_restriction_date, color=&#39;k&#39;, linestyle=&#39;dashed&#39;, linewidth=1) plt.tick_params(axis=&#39;both&#39;,labelsize=13) #plt.tick_params(axis=&#39;both&#39;,labelsize=13) axes = plt.gca() axes.set_ylim([-120, 220]) . (-120.0, 220.0) . long_regions_plot.savefig(f&#39;{locations_type}_lombardy.png&#39;, format=&#39;png&#39;, dpi=600) . Filtering using restriction dates (comment if you do not want to do this) . mês de fevereiro: mês atipico para os paises. possibilidade de usar ou não usar o mês de fevereiro. verificar a influencia disso na analise dos dados. | paramos de usar restrição de data nas regiões (que escolhemos) por causa da lombardia, e da data de inicio da coleta dos dados. | analisar se tiveram regiões que tomaram medidas de restrição antes do inicio da coleta dos dados. | . # data_period = data_by_days.query(&quot;n_days_since_restriction &gt;= -7 &amp; n_days_since_restriction &lt;= 50&quot;) . Inspecting . fig = px.line(data_period.sort_values(&#39;n_days_since_restriction&#39;), x=&quot;n_days_since_restriction&quot;, y=&quot;workplaces&quot;, color=&quot;locality_name&quot;, labels=plotly_labels, color_discrete_sequence = colors_sequence_locality) fig.show() . . . Centering the mean . calibrar as regiões (como a google fala) | . https://support.google.com/covid19-mobility/checklist/9834261?hl=pt-BR&amp;ref_topic=9822927 . data_period_small = data_period.query(&quot;date &lt;= &#39;2020-07-24&#39;&quot;).copy() data_period_small . date locality_name retail grocery_pharmacy parks transit_stations workplaces residential first_case_date restriction_date ease_restriction_date n_days_since_first_case n_days_since_restriction n_days_since_ease_restriction . 0 2020-02-15 | Lombardia | 3.076923 | -3.538462 | 42.307692 | 9.615385 | -1.076923 | -0.846154 | 2020-02-14 | 2020-02-23 | 2020-05-04 | 1 | -8 | -79 | . 1 2020-02-15 | New York | 9.096774 | -0.967742 | 16.892857 | 10.625000 | 0.387097 | -0.179487 | 2020-03-01 | 2020-03-15 | 2020-05-15 | -15 | -29 | -90 | . 2 2020-02-15 | Amazonas | -2.857143 | 5.750000 | -19.500000 | -5.333333 | 6.500000 | -1.000000 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -27 | -30 | -106 | . 3 2020-02-15 | São Paulo | 2.424528 | 1.944724 | 2.500000 | 1.007576 | 6.419355 | -0.676647 | 2020-02-26 | 2020-03-16 | 2020-06-01 | -11 | -30 | -107 | . 4 2020-02-15 | Île-de-France | -11.555556 | -10.444444 | 7.333333 | 3.222222 | -8.222222 | -1.222222 | 2020-01-23 | 2020-03-12 | 2020-05-11 | 23 | -26 | -86 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 800 2020-07-24 | Lombardia | -16.307692 | -12.307692 | 22.230769 | -38.153846 | -28.538462 | 6.000000 | 2020-02-14 | 2020-02-23 | 2020-05-04 | 161 | 152 | 81 | . 801 2020-07-24 | New York | -10.533333 | 6.701754 | 90.529412 | -18.848485 | -33.370968 | 8.928571 | 2020-03-01 | 2020-03-15 | 2020-05-15 | 145 | 131 | 70 | . 802 2020-07-24 | Amazonas | -21.400000 | 29.400000 | -17.400000 | -4.000000 | 6.062500 | 10.666667 | 2020-03-13 | 2020-03-16 | 2020-05-31 | 133 | 130 | 54 | . 803 2020-07-24 | São Paulo | -33.050251 | 9.626214 | -17.237762 | -29.462069 | -5.927184 | 12.551724 | 2020-02-26 | 2020-03-16 | 2020-06-01 | 149 | 130 | 53 | . 804 2020-07-24 | Île-de-France | -27.222222 | -13.444444 | 14.555556 | -29.555556 | -40.222222 | 7.444444 | 2020-01-23 | 2020-03-12 | 2020-05-11 | 183 | 134 | 74 | . 805 rows × 14 columns . long_centered_mean = centering_mean(data_period_small) long_centered_mean.head() . locality_name category baseline_mean date first_case_date restriction_date ease_restriction_date n_days_since_first_case n_days_since_restriction n_days_since_ease_restriction value . 0 Amazonas | retail | 0.703413 | 2020-02-15 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -27 | -30 | -106 | -3.560556 | . 1 Amazonas | retail | 0.703413 | 2020-02-16 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -26 | -29 | -105 | -5.370079 | . 2 Amazonas | retail | 0.703413 | 2020-02-17 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -25 | -28 | -104 | 2.796587 | . 3 Amazonas | retail | 0.703413 | 2020-02-18 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -24 | -27 | -103 | 4.796587 | . 4 Amazonas | retail | 0.703413 | 2020-02-19 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -23 | -26 | -102 | -7.303413 | . Inspecting workplaces . data_workplaces = long_centered_mean.query(&quot;category == &#39;workplaces&#39;&quot;).sort_values(&quot;date&quot;) fig = px.line(data_workplaces.sort_values(&#39;n_days_since_restriction&#39;), x=&quot;n_days_since_restriction&quot;, y=&quot;value&quot;, color=&quot;locality_name&quot;, labels=plotly_labels, color_discrete_sequence = colors_sequence_locality) fig.show() . . . Inspecting regions . fig = px.line(long_centered_mean, x=&quot;n_days_since_restriction&quot;, y=&quot;value&quot;, color=&quot;category&quot;, labels=plotly_labels, color_discrete_sequence = colors_sequence_category, facet_col=&quot;locality_name&quot;, facet_col_wrap=2, height=800) fig.show() . . . Shift to positive . não influenciar no calculo da auc e media | ter um ponto de referência comum para o calcula auc | . index_vars = [&quot;locality_name&quot;, &quot;date&quot;, &quot;first_case_date&quot;, &quot;restriction_date&quot;, &quot;ease_restriction_date&quot;, &quot;n_days_since_first_case&quot;, &quot;n_days_since_restriction&quot;, &quot;n_days_since_ease_restriction&quot;] long_centered_shifted = shift_positive(long_centered_mean.copy()) data_centered_shifted = long_centered_shifted.pivot_table(index=index_vars, columns=[&quot;category&quot;], values=&quot;value&quot;).reset_index() data_centered_shifted.head() . category locality_name date first_case_date restriction_date ease_restriction_date n_days_since_first_case n_days_since_restriction n_days_since_ease_restriction grocery_pharmacy parks residential retail transit_stations workplaces . 0 Amazonas | 2020-02-15 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -27 | -30 | -106 | 115.230256 | 103.757637 | 110.125256 | 108.266368 | 103.813034 | 108.107361 | . 1 Amazonas | 2020-02-16 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -26 | -29 | -105 | 111.813590 | 102.543352 | 112.125256 | 106.456844 | 108.146368 | 101.607361 | . 2 Amazonas | 2020-02-17 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -25 | -28 | -104 | 109.480256 | 123.257637 | 110.375256 | 114.623510 | 109.479701 | 121.829583 | . 3 Amazonas | 2020-02-18 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -24 | -27 | -103 | 107.280256 | 119.007637 | 110.375256 | 116.623510 | 122.146368 | 121.718472 | . 4 Amazonas | 2020-02-19 | 2020-03-13 | 2020-03-16 | 2020-05-31 | -23 | -26 | -102 | 104.080256 | 111.757637 | 110.375256 | 104.523510 | 119.646368 | 120.496250 | . Inspecting workplaces . long_workplaces_centered_shifted = long_centered_shifted.query(&quot;category == &#39;workplaces&#39;&quot;).sort_values(&quot;date&quot;) fig = px.line(long_workplaces_centered_shifted, x=&quot;n_days_since_restriction&quot;, y=&quot;value&quot;, color=&quot;locality_name&quot;, labels=plotly_labels, color_discrete_sequence=colors_sequence_locality) fig.show() . . . fig = px.line(data_centered_shifted, x=&quot;n_days_since_restriction&quot;, y=&quot;workplaces&quot;, color=&quot;locality_name&quot;, labels=plotly_labels, color_discrete_sequence=colors_sequence_locality) fig.show() . . . Inspecting regions . fig = px.line(long_centered_shifted, x=&quot;n_days_since_restriction&quot;, y=&quot;value&quot;, color=&quot;category&quot;, labels=plotly_labels, facet_col=&quot;locality_name&quot;, facet_col_wrap=2, height=800, color_discrete_sequence=colors_sequence_category) fig.show() . . . Seasonality . STL . extrair da tendencia ou amenizar a sazonaldade com a media movel | estramos querendo remover sazonalidade, usando dois metodos: stl: deveria isolar o ruido | media movel: remove a sazonalidade | . | . long_centered_shifted_trend = seasonality(long_centered_shifted.copy()) . Inspecting workplaces . long_centered_shifted_trend_workplaces = long_centered_shifted_trend.query(&quot;category == &#39;workplaces&#39;&quot;).sort_values(&quot;date&quot;) fig = px.line(long_centered_shifted_trend_workplaces, x=&quot;n_days_since_restriction&quot;, y=&quot;trend&quot;, color=&quot;locality_name&quot;, labels=plotly_labels, color_discrete_sequence=colors_sequence_locality) fig.show() . . . Inspecting regions . fig = px.line(long_centered_shifted_trend, x=&quot;n_days_since_restriction&quot;, y=&quot;trend&quot;, color=&quot;category&quot;, labels=plotly_labels, facet_col=&quot;locality_name&quot;, facet_col_wrap=2, height=800, color_discrete_sequence=colors_sequence_category) fig.show() . . . Rolling avg (7-day) . long_roll_mean = rolling_avg(long_centered_shifted_trend) . Inspecting workplaces . long_roll_mean_workplaces = long_roll_mean.query(&quot;category == &#39;parks&#39;&quot;).sort_values(&quot;n_days_since_restriction&quot;) fig = px.line(long_roll_mean_workplaces, x=&quot;n_days_since_restriction&quot;, y=&quot;rollavg&quot;, color=&quot;locality_name&quot;, labels=plotly_labels, color_discrete_sequence=colors_sequence_locality) fig.show() . . . Inspecting regions . fig = px.line(long_roll_mean, x=&quot;n_days_since_restriction&quot;, y=&quot;rollavg&quot;, color=&quot;category&quot;, labels=plotly_labels, facet_col=&quot;locality_name&quot;, facet_col_wrap=2, height=800, color_discrete_sequence=colors_sequence_category) fig.show() . . . Gathering all the data . janela de dias: 0 a 50 | . long_complete = pd.merge(long_centered_shifted_trend, long_roll_mean) long_complete_period = long_complete.query(&quot;50 &gt; n_days_since_restriction &gt;= 0&quot;) long_small_period = long_complete_period[[&quot;locality_name&quot;, &quot;n_days_since_restriction&quot;, &quot;category&quot;, &quot;raw&quot;, &quot;trend&quot;, &quot;rollavg&quot;]].copy() . . STL and MA before shitf to positive . long_centered_mean_seasonality = seasonality(long_centered_mean) long_centered_mean_ma = rolling_avg(long_centered_mean_seasonality) . long_centered_mean_seasonality_small = long_centered_mean_seasonality[[&quot;locality_name&quot;, &quot;category&quot;, &quot;date&quot;, &quot;n_days_since_restriction&quot;, &quot;n_days_since_ease_restriction&quot;, &quot;raw&quot;, &quot;trend&quot;]].copy() . long_centered_mean_stl_ma = pd.merge(long_centered_mean_seasonality_small, long_centered_mean_ma).melt( id_vars=[&quot;n_days_since_restriction&quot;, &quot;date&quot;, &quot;category&quot;, &quot;locality_name&quot;, &quot;n_days_since_ease_restriction&quot;], ) long_centered_mean_stl_ma.query(&quot;locality_name == &#39;Lombardia&#39; and category==&#39;parks&#39; and variable==&#39;raw&#39;&quot;) . n_days_since_restriction date category locality_name n_days_since_ease_restriction variable value . 8 -8 | 2020-02-15 | parks | Lombardia | -79 | raw | 22.173077 | . 38 -7 | 2020-02-16 | parks | Lombardia | -78 | raw | 0.019231 | . 68 -6 | 2020-02-17 | parks | Lombardia | -77 | raw | -30.057692 | . 98 -5 | 2020-02-18 | parks | Lombardia | -76 | raw | 5.634615 | . 128 -4 | 2020-02-19 | parks | Lombardia | -75 | raw | -0.750000 | . ... ... | ... | ... | ... | ... | ... | ... | . 4688 148 | 2020-07-20 | parks | Lombardia | 77 | raw | 43.480769 | . 4718 149 | 2020-07-21 | parks | Lombardia | 78 | raw | 54.711538 | . 4748 150 | 2020-07-22 | parks | Lombardia | 79 | raw | 39.557692 | . 4778 151 | 2020-07-23 | parks | Lombardia | 80 | raw | 40.250000 | . 4808 152 | 2020-07-24 | parks | Lombardia | 81 | raw | 2.096154 | . 161 rows × 7 columns . long_centered_mean_stl_ma.query(&quot;locality_name == &#39;Lombardia&#39; and category==&#39;parks&#39;&quot;).sort_values(&quot;variable&quot;) . n_days_since_restriction date category locality_name n_days_since_ease_restriction variable value . 8 -8 | 2020-02-15 | parks | Lombardia | -79 | raw | 22.173077 | . 3098 95 | 2020-05-28 | parks | Lombardia | 24 | raw | 0.326923 | . 3128 96 | 2020-05-29 | parks | Lombardia | 25 | raw | 1.865385 | . 3158 97 | 2020-05-30 | parks | Lombardia | 26 | raw | 21.711538 | . 3188 98 | 2020-05-31 | parks | Lombardia | 27 | raw | 25.480769 | . ... ... | ... | ... | ... | ... | ... | ... | . 7958 96 | 2020-05-29 | parks | Lombardia | 25 | trend | 29.062192 | . 7928 95 | 2020-05-28 | parks | Lombardia | 24 | trend | 20.505341 | . 7898 94 | 2020-05-27 | parks | Lombardia | 23 | trend | 12.171795 | . 9608 151 | 2020-07-23 | parks | Lombardia | 80 | trend | 25.643662 | . 7238 72 | 2020-05-05 | parks | Lombardia | 1 | trend | -62.907646 | . 483 rows × 7 columns . f = sns.relplot(data=long_centered_mean_stl_ma.query(&quot;locality_name == &#39;Lombardia&#39; and category==&#39;parks&#39;&quot;).sort_values(&quot;variable&quot;), x=&quot;date&quot;, y=&quot;value&quot;, hue=&quot;variable&quot;, col=&quot;locality_name&quot;, col_wrap=2, kind=&quot;line&quot;, height=6, legend=&quot;brief&quot;, aspect=1.5, markers=True, dashes=True, facet_kws={&#39;sharey&#39;: True, &#39;sharex&#39;: False}, palette=[&#39;green&#39;,&#39;maroon&#39;,&#39;black&#39;]) #brown, fuchsia f._legend.remove() plt.subplots_adjust(#left=0.125, bottom=0.1, #right=0.9, top=0.9, #wspace=0.2, hspace=0.35 ) # Iterate thorugh each axis for ax in f.axes: ax.set(xlabel=&#39;Date&#39;, ylabel=&#39;Value&#39;) handles, labels = ax.get_legend_handles_labels() #if handles: set_labels = [&quot;Raw&quot;, &quot;MA&quot;, &quot;Trend&quot;] ax.legend( labels=set_labels, title=&quot;&quot;, fancybox=True, framealpha=1, #shadow=True, borderpad=1, loc=&#39;upper left&#39;, fontsize=11, title_fontsize=11, #frameon=False, handleheight = 0.1, ) # Make x and y-axis labels slightly larger ax.set_xlabel(ax.get_xlabel(), fontsize=14) ax.set_ylabel(ax.get_ylabel(), fontsize=14) #set ticks every week ax.xaxis.set_major_locator(mdates.WeekdayLocator()) #set major ticks format ax.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b&#39;)) ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=5)) # Make title more human-readable and larger if ax.get_title(): ax.set_title(&quot;&quot;) # Make right ylabel more human-readable and larger if ax.texts: # This contains the right ylabel text txt = ax.texts[0] ax.text(txt.get_unitless_position()[0], txt.get_unitless_position()[1], txt.get_text().split(&#39;=&#39;)[1], transform=ax.transAxes, va=&#39;center&#39;, fontsize=&#39;xx-large&#39;) # Remove the original text ax.texts[0].remove() ax.fill_between(long_centered_mean_stl_ma.query(&quot;locality_name == &#39;Lombardia&#39; and category==&#39;parks&#39; and 50 &gt; n_days_since_restriction &gt;= 0&quot;)[&quot;date&quot;], -150, 100, color=&quot;gray&quot;, alpha=0.2) restriction_date = datetime.strptime(&#39;2020-02-23&#39;, &#39;%Y-%m-%d&#39;) ease_restriction_date = datetime.strptime(&quot;2020-05-11&quot;, &#39;%Y-%m-%d&#39;) plt.axvline(restriction_date, color=&#39;k&#39;, linestyle=&#39;dashed&#39;, linewidth=1) plt.axvline(ease_restriction_date, color=&#39;k&#39;, linestyle=&#39;dashed&#39;, linewidth=1) plt.tick_params(axis=&#39;both&#39;,labelsize=13) axes = plt.gca() axes.set_ylim([-120, 220]) . (-120.0, 220.0) . f.savefig(f&#39;{locations_type}_long_centered_mean_stl_ma.png&#39;, format=&#39;png&#39;, dpi=600) . il&#234; de france e lombadia . long_centered_mean_stl_ma.query(&quot;locality_name in [&#39;Lombardia&#39;, &#39;Île-de-France&#39;] and category==&#39;parks&#39;&quot;).sort_values(&quot;variable&quot;) . n_days_since_restriction date category locality_name n_days_since_ease_restriction variable value . 8 -8 | 2020-02-15 | parks | Lombardia | -79 | raw | 22.173077 | . 3296 83 | 2020-06-03 | parks | Île-de-France | 23 | raw | 8.423077 | . 3278 101 | 2020-06-03 | parks | Lombardia | 30 | raw | -14.365385 | . 3266 82 | 2020-06-02 | parks | Île-de-France | 22 | raw | 26.423077 | . 3248 100 | 2020-06-02 | parks | Lombardia | 29 | raw | 184.019231 | . ... ... | ... | ... | ... | ... | ... | ... | . 8078 100 | 2020-06-02 | parks | Lombardia | 29 | trend | 32.358690 | . 8096 82 | 2020-06-02 | parks | Île-de-France | 22 | trend | 23.902899 | . 8108 101 | 2020-06-03 | parks | Lombardia | 30 | trend | 25.634286 | . 8438 112 | 2020-06-14 | parks | Lombardia | 41 | trend | 8.098951 | . 7238 72 | 2020-05-05 | parks | Lombardia | 1 | trend | -62.907646 | . 966 rows × 7 columns . f = sns.relplot(data=long_centered_mean_stl_ma.query(&quot;locality_name in [&#39;Île-de-France&#39;, &#39;Lombardia&#39;] and category==&#39;parks&#39; and 50 &gt; n_days_since_restriction &gt;= 0&quot;).sort_values([&quot;variable&quot;, &quot;locality_name&quot;]), x=&quot;n_days_since_restriction&quot;, y=&quot;value&quot;, hue=&quot;locality_name&quot;, col=&quot;variable&quot;, col_wrap=3, kind=&quot;line&quot;, legend=&quot;brief&quot;, height=6, aspect=0.8, markers=True, dashes=True, facet_kws={&#39;sharey&#39;: True, &#39;sharex&#39;: False, &quot;size&quot;: 5}, linewidth=3, hue_order = [&#39;Île-de-France&#39;, &#39;Lombardia&#39;]) #height=6, palette=[&#39;red&#39;, &#39;coral&#39;] f._legend.remove() plt.subplots_adjust(#left=0.125, bottom=0.1, #right=0.9, top=0.9, #wspace=0.2, hspace=0.35 ) labels_dict = {&quot;raw&quot;: &quot;Raw&quot;, &quot;trend&quot;: &quot;Trend&quot;, &quot;rollavg&quot;: &quot;MA&quot;} # Iterate thorugh each axis for ax in f.axes: ax.set(xlabel=&#39;Days since restriction&#39;, ylabel=&#39;&#39;) handles, labels = ax.get_legend_handles_labels() #if handles: #set_labels = [&#39;Lombardia&#39;, &#39;Île-de-France&#39;] ax.legend( labels=labels[1:], title=&quot;&quot;, fancybox=True, framealpha=1, #shadow=True, borderpad=1, loc=&#39;upper right&#39;, fontsize=16, title_fontsize=18, #frameon=False, handleheight = 0.1, ) # Make x and y-axis labels slightly larger ax.set_xlabel(ax.get_xlabel(), fontsize=18) ax.set_ylabel(ax.get_ylabel(), fontsize=18) # #set ticks every week # ax.xaxis.set_major_locator(mdates.WeekdayLocator()) # #set major ticks format # ax.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b&#39;)) # ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=5)) # Make title more human-readable and larger if ax.get_title(): new_label = labels_dict.get(ax.get_title().split(&#39;=&#39;)[1].strip()) ax.set_title(new_label, fontsize=18) # Make right ylabel more human-readable and larger if ax.texts: # This contains the right ylabel text txt = ax.texts[0] ax.text(txt.get_unitless_position()[0], txt.get_unitless_position()[1], txt.get_text().split(&#39;=&#39;)[1], transform=ax.transAxes, va=&#39;center&#39;, fontsize=&#39;xx-large&#39;) # Remove the original text ax.texts[0].remove() ax.tick_params(labelsize=14) #ax.fill_between(long_centered_mean_stl_ma.query(&quot;locality_name == &#39;Lombardia&#39; and category==&#39;parks&#39; and 50 &gt; n_days_since_restriction &gt;= 0&quot;)[&quot;date&quot;], -150, 100, color=&quot;gray&quot;, alpha=0.2) # restriction_date = datetime.strptime(&#39;2020-02-23&#39;, &#39;%Y-%m-%d&#39;) # ease_restriction_date = datetime.strptime(&quot;2020-05-11&quot;, &#39;%Y-%m-%d&#39;) # plt.axvline(restriction_date, color=&#39;k&#39;, linestyle=&#39;dashed&#39;, linewidth=1) # plt.axvline(ease_restriction_date, color=&#39;k&#39;, linestyle=&#39;dashed&#39;, linewidth=1) # import matplotlib # plt.tick_params(labelsize=12) axes = plt.gca() axes.set_ylim([-120, 100]) . /usr/local/lib/python3.6/dist-packages/seaborn/axisgrid.py:243: UserWarning: The `size` parameter has been renamed to `height`; please update your code. . (-120.0, 100.0) . import matplotlib._color_data as mcd overlap = {name for name in mcd.CSS4_COLORS if &quot;xkcd:&quot; + name in mcd.XKCD_COLORS} overlap . f.savefig(f&#39;{locations_type}_long_centered_mean_stl_ma_lombardia_ile.png&#39;, format=&#39;png&#39;, dpi=600) . Computing metrics . rank não se importa com o valor da redução, ele se importa com a frequência da redução. &quot;quem foi mais vezes bem sucedido&quot; e não &quot;por quanto foi bem sucedido&quot; | duas medidas parametricas e uma não (rank) | . index_cols = [&quot;n_days_since_restriction&quot;, &quot;locality_name&quot;, &quot;category&quot;] long_small_period_timedelta = long_small_period.copy() long_small_period_timedelta[&quot;n_days_since_restriction&quot;] = pd.to_timedelta(long_small_period[&quot;n_days_since_restriction&quot;], unit=&#39;D&#39;) . For a single window . long_small_period_timedelta_grouped50 = long_small_period_timedelta.groupby(pd.Grouper(key=&#39;n_days_since_restriction&#39;, freq=&#39;50D&#39;)) . long_small_period . locality_name n_days_since_restriction category raw trend rollavg . 246 Lombardia | 0 | retail | 93.057692 | 100.546279 | 108.640110 | . 247 Lombardia | 0 | grocery_pharmacy | 122.615385 | 114.723866 | 113.780220 | . 248 Lombardia | 0 | parks | 101.307692 | 106.839176 | 107.153846 | . 249 Lombardia | 0 | transit_stations | 96.413462 | 91.459244 | 108.237637 | . 250 Lombardia | 0 | workplaces | 109.163462 | 102.137171 | 111.581044 | . ... ... | ... | ... | ... | ... | ... | . 2389 São Paulo | 49 | grocery_pharmacy | 99.872640 | 102.726109 | 97.473127 | . 2390 São Paulo | 49 | parks | 77.980310 | 78.209552 | 78.363070 | . 2391 São Paulo | 49 | transit_stations | 65.747592 | 64.892561 | 63.498957 | . 2392 São Paulo | 49 | workplaces | 83.163505 | 78.607534 | 75.416396 | . 2393 São Paulo | 49 | residential | 126.232208 | 126.911048 | 127.401679 | . 1500 rows × 6 columns . results_complete, long_results_complete = computing_metrics(long_small_period_timedelta_grouped50) long_results_complete . n_days_since_restriction category locality_name agg metric value . 0 0 days | grocery_pharmacy | Amazonas | mean | raw | 91.350923 | . 1 0 days | grocery_pharmacy | Lombardia | mean | raw | 77.512308 | . 2 0 days | grocery_pharmacy | New York | mean | raw | 97.747342 | . 3 0 days | grocery_pharmacy | São Paulo | mean | raw | 94.664313 | . 4 0 days | grocery_pharmacy | Île-de-France | mean | raw | 79.018376 | . ... ... | ... | ... | ... | ... | ... | . 265 0 days | workplaces | Amazonas | auc | rollavg | 3884.429474 | . 266 0 days | workplaces | Lombardia | auc | rollavg | 3215.410714 | . 267 0 days | workplaces | New York | auc | rollavg | 3563.066347 | . 268 0 days | workplaces | São Paulo | auc | rollavg | 3778.722632 | . 269 0 days | workplaces | Île-de-France | auc | rollavg | 2530.217643 | . 270 rows × 6 columns . fig = px.line_polar(long_results_complete.query(&quot;agg==&#39;auc&#39;&quot;), r=&quot;value&quot;, theta=&quot;category&quot;, color=&quot;locality_name&quot;, animation_frame=&quot;metric&quot;, labels=plotly_labels, line_close=True) fig.layout.polar.radialaxis.range = [min(long_results_complete.query(&quot;agg==&#39;auc&#39;&quot;)[&quot;value&quot;]), max(long_results_complete.query(&quot;agg==&#39;auc&#39;&quot;)[&quot;value&quot;])] fig.show() . . . Inspecting categories . long_results_workplaces = long_results_complete.query(&quot;category == &#39;workplaces&#39;&quot;).drop(&quot;category&quot;, axis=1) data_results_workplaces = long_results_workplaces.pivot_table(index=&quot;locality_name&quot;, columns=[&quot;agg&quot;, &quot;metric&quot;], values=&quot;value&quot;) data_results_workplaces.rank().sort_values((&quot;auc&quot;,&quot;raw&quot;)).style .set_precision(0) .set_properties(**df_style) .apply(bg_color, cmap=&#39;PuBu&#39;) . agg auc mean rank . metric raw rollavg trend raw rollavg trend raw rollavg trend . locality_name . Île-de-France 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | . Lombardia 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | . New York 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | . São Paulo 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | . Amazonas 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . #print(data_results_workplaces.rank().sort_values((&quot;auc&quot;,&quot;raw&quot;)).to_latex(index=False)) . regiões . auc e mean tem resultados iguais. rank muda das outras medidas de agregamento somente no raw. | NY esta no ultimo em raw e trend (menos quando é no rank/raw), porém no rollavg ele troca com o Amazonas | . long_results_grocery_pharmacy = long_results_complete.query(&quot;category == &#39;grocery_pharmacy&#39;&quot;).drop(&quot;category&quot;, axis=1) data_results_grocery_pharmacy = long_results_grocery_pharmacy.pivot_table(index=&quot;locality_name&quot;, columns=[&quot;agg&quot;, &quot;metric&quot;], values=&quot;value&quot;) data_results_grocery_pharmacy.rank().sort_values((&quot;mean&quot;,&quot;raw&quot;)).style .set_precision(0) .set_properties(**df_style) .apply(bg_color, cmap=&#39;PuBu&#39;) . agg auc mean rank . metric raw rollavg trend raw rollavg trend raw rollavg trend . locality_name . Lombardia 1 | 2 | 1 | 1 | 2 | 1 | 2 | 2 | 2 | . Île-de-France 2 | 1 | 2 | 2 | 1 | 2 | 1 | 1 | 1 | . Amazonas 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | . São Paulo 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | . New York 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . data_results_grocery_pharmacy.head() . agg auc mean rank . metric raw rollavg trend raw rollavg trend raw rollavg trend . locality_name . Amazonas 4455.565897 | 4504.655183 | 4477.651070 | 91.350923 | 92.184352 | 91.693439 | 162.0 | 140.0 | 148.0 | . Lombardia 3805.346154 | 3959.912088 | 3784.170761 | 77.512308 | 80.963077 | 77.401843 | 114.0 | 118.0 | 111.0 | . New York 4768.812635 | 4850.637476 | 4771.220309 | 97.747342 | 99.261617 | 97.730099 | 195.0 | 214.0 | 214.0 | . São Paulo 4626.737175 | 4680.498404 | 4641.320726 | 94.664313 | 95.720506 | 94.982894 | 180.0 | 176.0 | 180.0 | . Île-de-France 3842.878205 | 3937.124237 | 3815.090103 | 79.018376 | 80.704090 | 78.292794 | 99.0 | 102.0 | 97.0 | . long_results_parks = long_results_complete.query(&quot;category == &#39;parks&#39;&quot;).drop(&quot;category&quot;, axis=1) data_results_parks = long_results_parks.pivot_table(index=&quot;locality_name&quot;, columns=[&quot;agg&quot;, &quot;metric&quot;], values=&quot;value&quot;) data_results_parks.rank().sort_values((&quot;mean&quot;,&quot;raw&quot;)).style .set_precision(0) .set_properties(**df_style) .apply(bg_color, cmap=&#39;PuBu&#39;) . agg auc mean rank . metric raw rollavg trend raw rollavg trend raw rollavg trend . locality_name . Lombardia 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 | . Île-de-France 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | . Amazonas 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | . São Paulo 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | . New York 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . For multiple windows . long_small_period_timedelta_grouped_10D = long_small_period_timedelta.groupby(pd.Grouper(key=&#39;n_days_since_restriction&#39;, freq=&#39;10D&#39;)) results_complete_10D, long_results_complete_10D = computing_metrics(long_small_period_timedelta_grouped_10D) . Inspecting categories . long_results_workplaces_10D = long_results_complete_10D.query(&quot;category == &#39;workplaces&#39;&quot;).drop(&quot;category&quot;, axis=1) long_results_workplaces_10D[&quot;n_days_since_restriction&quot;] = long_results_workplaces_10D[&quot;n_days_since_restriction&quot;].dt.days px.line( data_frame=long_results_workplaces_10D, x=&quot;n_days_since_restriction&quot;, y=&quot;value&quot;, color=&quot;locality_name&quot;, facet_col=&quot;metric&quot;, animation_frame=&quot;agg&quot;, ) . . . long_results_complete_10D . n_days_since_restriction category locality_name agg metric value . 0 0 days | grocery_pharmacy | Amazonas | mean | raw | 98.281923 | . 1 0 days | grocery_pharmacy | Lombardia | mean | raw | 109.061538 | . 2 0 days | grocery_pharmacy | New York | mean | raw | 112.354519 | . 3 0 days | grocery_pharmacy | São Paulo | mean | raw | 98.898764 | . 4 0 days | grocery_pharmacy | Île-de-France | mean | raw | 103.829487 | . ... ... | ... | ... | ... | ... | ... | . 1345 40 days | workplaces | Amazonas | auc | rollavg | 654.152935 | . 1346 40 days | workplaces | Lombardia | auc | rollavg | 388.432692 | . 1347 40 days | workplaces | New York | auc | rollavg | 622.775376 | . 1348 40 days | workplaces | São Paulo | auc | rollavg | 688.667587 | . 1349 40 days | workplaces | Île-de-France | auc | rollavg | 410.529609 | . 1350 rows × 6 columns . long_results_workplaces_10D.query(&quot;agg==&#39;rank&#39;&quot;) . n_days_since_restriction locality_name agg metric value . 475 0 | Amazonas | rank | raw | 40.0 | . 476 0 | Lombardia | rank | raw | 33.0 | . 477 0 | New York | rank | raw | 24.0 | . 478 0 | São Paulo | rank | raw | 30.0 | . 479 0 | Île-de-France | rank | raw | 23.0 | . ... ... | ... | ... | ... | ... | . 895 40 | Amazonas | rank | rollavg | 40.0 | . 896 40 | Lombardia | rank | rollavg | 10.0 | . 897 40 | New York | rank | rollavg | 30.0 | . 898 40 | São Paulo | rank | rollavg | 50.0 | . 899 40 | Île-de-France | rank | rollavg | 20.0 | . 75 rows × 5 columns . f = sns.relplot(data=long_results_workplaces_10D.query(&quot;agg==&#39;rank&#39;&quot;), x=&quot;n_days_since_restriction&quot;, y=&quot;value&quot;, hue=&quot;locality_name&quot;, col=&quot;metric&quot;, col_wrap=3, kind=&quot;line&quot;, legend=&quot;brief&quot;, aspect=1, markers=True, dashes=True, marker=&#39;o&#39;, facet_kws={&quot;size&quot;: 3}) #height=7, f._legend.remove() # Iterate thorugh each axis default_labels = None for ax in f.axes: ax.set(xlabel=&#39;Days since restriction&#39;, ylabel=&#39;Value&#39;) handles, labels = ax.get_legend_handles_labels() if labels: default_labels = labels # ax.legend( # #labels=default_labels[1:], # title=&quot;Categories&quot;, # fancybox=True, # #framealpha=1, # #shadow=True, # borderpad=1, # loc=&#39;upper right&#39;, # fontsize=12, # #frameon=False, # ncol=2, # handleheight = 0.1, # ) # plt.setp(axes[-1].get_xticklabels(), visible=True, rotation=35) # Make x and y-axis labels slightly larger ax.set_xlabel(ax.get_xlabel(), fontsize=12) ax.set_ylabel(ax.get_ylabel(), fontsize=12) # ax.xaxis.set_major_locator(1) # Make title more human-readable and larger if ax.get_title(): final_txt = ax.get_title().split(&#39;=&#39;)[1].strip().capitalize() if &quot;Rollavg&quot; in final_txt: final_txt = &quot;MA&quot; ax.set_title(final_txt, fontsize=12) # Make right ylabel more human-readable and larger if ax.texts: # This contains the right ylabel text txt = ax.texts[0] ax.text(txt.get_unitless_position()[0], txt.get_unitless_position()[1], txt.get_text().split(&#39;=&#39;)[1], transform=ax.transAxes, va=&#39;center&#39;, fontsize=&#39;xx-large&#39;) # Remove the original text ax.texts[0].remove() # f.subplots_adjust(bottom=0.3, wspace=0.33) import matplotlib.ticker as plticker loc = plticker.MultipleLocator(base=10) # this locator puts ticks at regular intervals ax.xaxis.set_major_locator(loc) f.axes[0].legend(title=&quot;&quot;, labels=default_labels[1:], loc=&#39;center&#39;, bbox_to_anchor=(1.5, -0.5), fancybox=False, shadow=False, ncol=5, fontsize=12) . /usr/local/lib/python3.6/dist-packages/seaborn/axisgrid.py:243: UserWarning: The `size` parameter has been renamed to `height`; please update your code. . &lt;matplotlib.legend.Legend at 0x7f418d332a58&gt; . f.savefig(f&#39;{locations_type}_long_results_workplaces_10D_rank.png&#39;, format=&#39;png&#39;, dpi=600) # dpi=100 . paises . em todas as situações a Espanha é melhor que a Corea do Sul salvo em casos pontuais, analisando na janela de 10D usando rank conseguimos ver que a Corea do Sul fica melhor que a espanha (combinação entre preprocessamento, metrica e granularidade temporal) . | notar que quando trabalhamos com janela 50D perdemos a noção do comportamento no tempo . Espanha: começa mal, tem queda e consegue se manter. | Nova Zelandia: começa bem e piora. | . | observar espanha e alemanha (na janela que inicia em 0): ruido no dado original é observavel | no trend o ruido é amenizado (as duas começam em ponto proximo) | e no rollavg o efeito do ruido é potencializado (a diferença é maior que no raw) | . | . regiões . notar que quando trabalhamos com janela 50D perdemos a noção do comportamento no tempo Lombardia começa mal, tem queda e termina bem | NY começa &quot;bem&quot;, e piora | . | . long_results_grocery_10D = long_results_complete_10D.query(&quot;category == &#39;grocery_pharmacy&#39;&quot;).drop(&quot;category&quot;, axis=1) long_results_grocery_10D[&quot;n_days_since_restriction&quot;] = long_results_grocery_10D[&quot;n_days_since_restriction&quot;].dt.days px.line( data_frame=long_results_grocery_10D, x=&quot;n_days_since_restriction&quot;, y=&quot;value&quot;, color=&quot;locality_name&quot;, facet_col=&quot;metric&quot;, animation_frame=&quot;agg&quot;, ) . para grocery pharmy o efeito tbm é observado: na janela zero paises como espanha e canada se tornam os piores segundo o rollavg. | . long_results_parks_10D = long_results_complete_10D.query(&quot;category == &#39;parks&#39;&quot;).drop(&quot;category&quot;, axis=1) long_results_parks_10D[&quot;n_days_since_restriction&quot;] = long_results_parks_10D[&quot;n_days_since_restriction&quot;].dt.days px.line( data_frame=long_results_parks_10D, x=&quot;n_days_since_restriction&quot;, y=&quot;value&quot;, color=&quot;locality_name&quot;, facet_col=&quot;metric&quot;, animation_frame=&quot;agg&quot;, ) . para parks temos um grupo bem claro a partir da janela 10D (argentina, nova zelandia e espanha). | o segundo grupo de paises é afetado por todos os fatores considerados. | . Save . !git config --global user.email &quot;mo-covid19@gmail.com&quot; !git config --global user.name &quot;mo-covid19&quot; . long_small_period.to_csv(f&#39;mo_covid19/{locations_type}/long_small_period.csv&#39;) long_results_complete.to_csv(f&#39;mo_covid19/{locations_type}/long_results_complete.csv&#39;) long_results_complete_10D.to_csv(f&#39;mo_covid19/{locations_type}/long_results_complete_10D.csv&#39;) !cd mo_covid19 &amp;&amp; git add . &amp;&amp; git commit -m &quot;update data csv&quot; &amp;&amp; git push .",
            "url": "https://gabicavalcante.github.io/mcdm-covid19/2020/08/22/MO-COVID19-Preprocessing.html",
            "relUrl": "/2020/08/22/MO-COVID19-Preprocessing.html",
            "date": " • Aug 22, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://gabicavalcante.github.io/mcdm-covid19/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://gabicavalcante.github.io/mcdm-covid19/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://gabicavalcante.github.io/mcdm-covid19/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://gabicavalcante.github.io/mcdm-covid19/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}